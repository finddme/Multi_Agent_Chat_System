{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca3a924-c770-4e44-a3f1-bbf9b8d7a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scores_to_ranking(scores: list[float]) -> list[int]:\n",
    "    return np.argsort(scores)[::-1] + 1\n",
    "\n",
    "\n",
    "def rrf(keyword_rank: int, semantic_rank: int) -> float:\n",
    "    k = 60\n",
    "    rrf_score = 1 / (k + keyword_rank) + 1 / (k + semantic_rank)\n",
    "    return rrf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "693c2e5b-8361-4642-8dd4-3918456e2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "def bm25_keyword_search(corpus,query):\n",
    "    tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "    tokenized_query = query.split(\" \")\n",
    "    \n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    doc_scores = list(bm25.get_scores(tokenized_query)) # score\n",
    "    doc_top_n=bm25.get_top_n(tokenized_query, corpus, n=1) # top_n\n",
    "\n",
    "    # map_res= map(lambda score, c: {\"score\": score, \"sentence\": c}, doc_scores, corpus)\n",
    "    res=list(map(lambda score, sentence: {\"score\": score, \"sentence\": sentence}, doc_scores, corpus))\n",
    "    \n",
    "    return doc_scores\n",
    "    \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "embedd_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "def semantic_search(corpus,query):\n",
    "    document_embeddings = embedd_model.encode(corpus)\n",
    "    embedding_shape=document_embeddings.shape\n",
    "    \n",
    "    query_embedding = embedd_model.encode(query)\n",
    "    \n",
    "    scores = cos_sim(document_embeddings, query_embedding)\n",
    "    scores=sum(scores.tolist(),[])\n",
    "    \n",
    "    res=list(map(lambda score, sentence: {\"score\": score, \"sentence\": sentence}, scores, corpus))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb5ce32-0699-48ca-838b-34a9225ae5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"최근 생성형 모델과 함께 사용되는 RAG의 retrieval 단계에서는 qeury와 유사한 chunk를 찾는 것이 매우 중요하다. 검색된 chunk가 모델에 참고 문서로 입력되기 때문에 유사도 검색 결과가 최종 결과에 큰 영향을 미친다.\",\n",
    "    \"Semantic Search는 text를 모델을 통해 embedding시킨 후 embedding vector들의 거리를 통해 유사도를 검색하는 방법이다.\",\n",
    "    \"BM25는 TF-IDF 알고리즘을 기반으로 한 키워드 검색 알고리즘이다. 매우 오래된 알고리즘이고, 이를 기반으로 한 여러 variation들이 제안되었지만 keyword search에 있어서 아직까지는 클래식이 베스트이다.\",\n",
    "    \"사용자의 질문이 명확하지 않은 경우, similarity search 과정에서 오류가 발생할 수 있다.\"\n",
    "]\n",
    "query = \"Semantic Search 방법에 대해 알려줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f608bdb-ea51-4fb2-b887-8b33f1a71a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_score=bm25_keyword_search(corpus,query)\n",
    "s_score=semantic_search(corpus,query)\n",
    "\n",
    "k_rank=scores_to_ranking(k_score)\n",
    "s_rank=scores_to_ranking(s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52dc8876-d837-48d1-a235-9663076f199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "def hybrid_search(\n",
    "    corpus: list[str], query: str, encoder_model=embedd_model) -> list[int]:\n",
    "    k_score=bm25_keyword_search(corpus,query)\n",
    "    s_score=semantic_search(corpus,query)\n",
    "    \n",
    "    k_rank=scores_to_ranking(k_score)\n",
    "    s_rank=scores_to_ranking(s_score)\n",
    "\n",
    "    hybrid_scores = []\n",
    "    for i, doc in enumerate(corpus):\n",
    "        document_ranking = rrf(k_rank[i], s_rank[i])\n",
    "        hybrid_scores.append(document_ranking)\n",
    "\n",
    "    hybrid_ranking = list(scores_to_ranking(hybrid_scores))\n",
    "    \n",
    "    res=list(map(lambda rank, sentence: {\"rank\": rank, \"sentence\": sentence}, hybrid_ranking, corpus))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73dabff0-90a1-4aa9-8e62-8907f8f159b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rank': 4,\n",
       "  'sentence': '최근 생성형 모델과 함께 사용되는 RAG의 retrieval 단계에서는 qeury와 유사한 chunk를 찾는 것이 매우 중요하다. 검색된 chunk가 모델에 참고 문서로 입력되기 때문에 유사도 검색 결과가 최종 결과에 큰 영향을 미친다.'},\n",
       " {'rank': 1,\n",
       "  'sentence': 'Semantic Search는 text를 모델을 통해 embedding시킨 후 embedding vector들의 거리를 통해 유사도를 검색하는 방법이다.'},\n",
       " {'rank': 3,\n",
       "  'sentence': 'BM25는 TF-IDF 알고리즘을 기반으로 한 키워드 검색 알고리즘이다. 매우 오래된 알고리즘이고, 이를 기반으로 한 여러 variation들이 제안되었지만 keyword search에 있어서 아직까지는 클래식이 베스트이다.'},\n",
       " {'rank': 2,\n",
       "  'sentence': '사용자의 질문이 명확하지 않은 경우, similarity search 과정에서 오류가 발생할 수 있다.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search(corpus,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e76ca-e336-4367-817d-09e5eedea9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
