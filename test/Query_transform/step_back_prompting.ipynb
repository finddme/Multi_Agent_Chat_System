{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "777ec871-a393-48a6-a5d9-3c85b61a002b",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_anthropic import ChatAnthropic\n",
                "claude_api_key=\"\"\n",
                "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\",api_key=claude_api_key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "c291a778-f82b-41f7-bfb2-ef531c6c0b6a",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "from langchain_core.pydantic_v1 import BaseModel, Field\n",
                "from typing import Literal\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "def step_back_prompting(query):\n",
                "    prompt = ChatPromptTemplate.from_template(\n",
                "        \"\"\"You are an expert software engineer. \n",
                "        Your task is to rephrase the given question into a more general form that is easier to answer.\n",
                "        The output should be in Korean.\n",
                "        \n",
                "        # Example 1\n",
                "        Question: How to improve Django performance?\n",
                "        Output: what factors impact web app performance?\n",
                "        \n",
                "        # Example 2\n",
                "        Question: How to optimize browser cache in Django?\n",
                "        Output: What are the different caching options?\n",
                "        \n",
                "        \n",
                "        Question: {question}\n",
                "        Output:\n",
                "        \"\"\"\n",
                "        )\n",
                "    \n",
                "    # Chain\n",
                "    step_back_prompt_chain = prompt | llm | StrOutputParser()\n",
                "    generation = step_back_prompt_chain.invoke({\"question\": query})\n",
                "    return generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "7ef11b33-328c-4080-841d-4d0415ad4bde",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'최근 몇 년간 주목받은 인공지능 언어 모델들의 특징과 발전 동향은 무엇인가요?'"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "query=\"2022년부터 2023년 사이에 가장 주목 받은 LLM 모델들에 대해 설명해주세요. \"\n",
                "step_back_prompting(query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fdbb4a1a-e1d7-464e-9387-ef17768c073c",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}