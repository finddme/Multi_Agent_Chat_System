{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "552fa82b-5cb8-4334-a0a6-fbbb7e0ac1a1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_anthropic import ChatAnthropic\n",
                "claude_api_key=\"\"\n",
                "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\",api_key=claude_api_key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "d2ff82b1-0685-4248-a1c1-cc6c818b0453",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "RouteQuery(datasource='AI')"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_core.pydantic_v1 import BaseModel, Field\n",
                "from typing import Literal\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "class RouteQuery(BaseModel):\n",
                "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
                "\n",
                "    datasource: Literal[\"AI\", \"Law\", \"Social\", \"Other\"] = Field(\n",
                "        ...,\n",
                "        description=\"Given a user question choose to route it to AI or Law or Social or other.\",\n",
                "    )\n",
                "\n",
                "def query_router(query):\n",
                "    structured_llm_router = llm.with_structured_output(RouteQuery)\n",
                "    \n",
                "    system = \"\"\"You are an expert at routing a user question to a vectorstore or web search or casual conversation.\n",
                "    The vectorstore contains documents related to language processing, and artificial intelligence.\n",
                "    Use the vectorstore for questions on these topics. For all else, use web-search.\n",
                "    If the question is a casual conversation use original knowledge\"\"\"\n",
                "    route_prompt = ChatPromptTemplate.from_messages(\n",
                "        [\n",
                "            (\"system\", system),\n",
                "            (\"human\", \"{question}\"),\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    question_router = route_prompt | structured_llm_router\n",
                "    result=question_router.invoke({\"question\": query})\n",
                "\n",
                "    return result\n",
                "\n",
                "query=\"2022년부터 2023년 사이에 가장 주목 받은 LLM 모델들에 대해 설명해주세요. \"\n",
                "query_router(query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bf181405-7d1b-4b4e-9d85-b6b43cb6dc26",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}