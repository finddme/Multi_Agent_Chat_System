{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "d11288c5-5aa1-4a70-b0fd-838c7391be70",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_anthropic import ChatAnthropic\n",
                "claude_api_key=\"\"\n",
                "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\",api_key=claude_api_key)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2d0045a2-2e11-437f-ac50-03de84048996",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.pydantic_v1 import BaseModel, Field\n",
                "from typing import Literal\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "def completion_router(query):\n",
                "    prompt = ChatPromptTemplate.from_template(\n",
                "        \"\"\"Given the user question below, classify it as either\n",
                "        being about `AI`, `Law`, `Social`, or `Other`.\n",
                "        \n",
                "        Do not respond with more than one word.\n",
                "        \n",
                "        <question>\n",
                "        {question}\n",
                "        </question>\n",
                "        \n",
                "        Classification:\n",
                "        \"\"\"\n",
                "        )\n",
                "    \n",
                "    # Chain\n",
                "    completion_router_chain = prompt | llm | StrOutputParser()\n",
                "    generation = completion_router_chain.invoke({\"question\": query})\n",
                "    return generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "b646a24b-0e6f-45db-9e4f-097750dd544a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'AI'"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "query=\"2022년부터 2023년 사이에 가장 주목 받은 LLM 모델들에 대해 설명해주세요. \"\n",
                "completion_router(query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c081f586-9ab0-46d8-95bc-589cad5f15cd",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "61babdf4-2abf-4047-b43b-2ec779d6b00c",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eae886fa-995d-4402-be63-69bfae14e742",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}